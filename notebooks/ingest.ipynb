{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percorre todos os diretórios a partir de um diretório raiz (URL) e extrai as informações, devolvendo uma lista de 'Document'. As informações extraidas são:\n",
    "- **page_content** -> _Conteúdo da página_\n",
    "- **metadata:**\n",
    "    - **source** -> _URL lida_\n",
    "    - **title** -> _Título da página_\n",
    "    - **description** -> _Descrição do conteúdo da página_\n",
    "    - **language** -> _Idioma da página_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "import os\n",
    "import re\n",
    "import logging\n",
    "\n",
    "from langchain_community.document_loaders.recursive_url_loader import RecursiveUrlLoader\n",
    "from bs4 import BeautifulSoup as Soup\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain.vectorstores.weaviate import Weaviate\n",
    "from langchain.indexes import index, SQLRecordManager\n",
    "from langchain.utils.html import PREFIXES_TO_IGNORE_REGEX, SUFFIXES_TO_IGNORE_REGEX\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "PREFIX_URL = 'https://ai.stackspot.com'\n",
    "\n",
    "url = f'{PREFIX_URL}/docs/'\n",
    "\n",
    "def simple_extractor(html: str) -> str:\n",
    "    soup = Soup(html, \"lxml\")\n",
    "    return re.sub(r\"\\n\\n+\", \"\\n\\n\", soup.text.encode('latin1').decode('utf-8')).strip()\n",
    "\n",
    "def load_api_docs(): \n",
    "    return RecursiveUrlLoader(\n",
    "        url=url,\n",
    "        max_depth=10,\n",
    "        extractor=simple_extractor,\n",
    "        #Pode ser usado fora do notebook jupyter\n",
    "        #use_async=True,\n",
    "        link_regex=(\n",
    "            f\"href=[\\\"']{PREFIXES_TO_IGNORE_REGEX}((?:{SUFFIXES_TO_IGNORE_REGEX}.)*?)\"\n",
    "            r\"(?:[\\#'\\\"]|\\/[\\#'\\\"])\"\n",
    "        ),\n",
    "        check_response_status=True,\n",
    ").load()\n",
    "\n",
    "docs = load_api_docs()\n",
    "logger.info(f\"Document example: {docs[0]}\")\n",
    "\n",
    "sources = []\n",
    "\n",
    "for source in docs:\n",
    "    directory = source.metadata['source'].replace(PREFIX_URL, \"\")\n",
    "    sources.append(directory)\n",
    "\n",
    "logger.info(f'URLs found: {sources}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alimenta o vectorstore com as informações dos 'Documents' e cria uma tabela no PostgreSQL com o UUID, a chave, namespace, group_id e updated_at dos objetos do vectorstore para o gerenciamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEAVIATE_DOCS_INDEX_NAME = 'My_Docs_Index_Name'\n",
    "WEAVIATE_URL = 'http://localhost:8080'\n",
    "RECORD_MANAGER_DB_URL = 'postgresql://postgres:123admin@localhost'\n",
    "\n",
    "def get_embeddings_model() -> Embeddings:\n",
    "    return OpenAIEmbeddings(model=\"text-embedding-3-small\", chunk_size=200)\n",
    "\n",
    "def ingest_docs():\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=4000, chunk_overlap=200)\n",
    "    client = weaviate.Client(\n",
    "        url=WEAVIATE_URL\n",
    "    )\n",
    "    embedding = get_embeddings_model()\n",
    "    vectorstore = Weaviate(\n",
    "        client=client,\n",
    "        index_name=WEAVIATE_DOCS_INDEX_NAME,\n",
    "        text_key=\"text\",\n",
    "        embedding=embedding,\n",
    "        by_text=False,\n",
    "        attributes=[\"source\", \"title\"],\n",
    "    )\n",
    "\n",
    "    docs_from_documentation = text_splitter.split_documents(docs)\n",
    "\n",
    "    for doc in docs_from_documentation:\n",
    "        if \"source\" not in doc.metadata:\n",
    "            doc.metadata['source'] = \"\"\n",
    "        if \"title\" not in doc.metadata:\n",
    "            doc.metadata['title'] = \"\"\n",
    "\n",
    "    record_manager = SQLRecordManager(\n",
    "        f\"weaviate/{WEAVIATE_DOCS_INDEX_NAME}\", db_url=RECORD_MANAGER_DB_URL\n",
    "    )\n",
    "\n",
    "    record_manager.create_schema()\n",
    "    \n",
    "    indexing_stats = index(\n",
    "        docs_from_documentation,\n",
    "        record_manager,\n",
    "        vectorstore,\n",
    "        cleanup=\"full\",\n",
    "        source_id_key=\"source\",\n",
    "        force_update=(os.environ.get(\"FORCE_UPDATE\") or \"false\").lower() == \"true\",\n",
    "    )\n",
    "\n",
    "    logger.info(f\"Index Stats:  {indexing_stats}\")\n",
    "\n",
    "ingest_docs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
